---
title: "P8105_HW6_jl7035"
author: "Jeffrey Lin"
date: "2024-12-02"
output: html_document
---

# Load Libraries
```{r}
library(tidyverse)

```

# Problem 1 

## Load and Clean Data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

```
## Peform Boostrap
```{r}
bootstrap_df <- weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, \(samp) lm(tmax ~ tmin, data = samp)),
    results = map(models, broom::tidy),
    summary = map(models, broom::glance),
    r_squared = map_dbl(summary, \(x) x$r.squared),
    log_beta_prod = map_dbl(results, \(x) log(prod(x$estimate)))
  ) %>% 
  select(-models,-results, -summary, -strap)
```

## Distribution of R-squared

```{r}
bootstrap_df %>% 
  ggplot(aes(x = r_squared)) +
  geom_density() + 
  xlab(label = "R-Squared") +
  ggtitle(label = "Distribution of R-Squared Values")

```
Examining the distribution of R-squared values, it appears that the R-squared 
for a linear model with minimum temperature as a predictor of max temperature 
tends to center at a little above 0.91. 

## Distribution of log(beta_1 * beta_0)

```{r}
bootstrap_df %>% 
  ggplot(aes(x = log_beta_prod)) + 
  geom_density() +
  xlab(label = "Log(Beta_0 * Beta_1") +
  ggtitle(label = "Distribution of Log(Beta_0 * Beta_1)")
```
Examining the distribution of Log(Beta_0 * Beta_1) values, it appears that the
values for a linear model with minimum temperature as a predictor of max temperature 
tends to center between 2.00 and 2.025. 

## Identify 95% confidence Interval for R-Squared

```{r}
bootstrap_df %>% 
  summarize(
    lower_ci = quantile(r_squared, 0.025), 
    upper_ci = quantile(r_squared, 0.975)
  )
```
## Identify the 95% confidence interval of Log (Beta_0 * Beta_1) 

```{r}
bootstrap_df %>% 
  summarize(
    lower_ci = quantile(log_beta_prod, 0.025), 
    upper_ci = quantile(log_beta_prod, 0.975)
  )
```

# Problem 2 

## Load in Data
```{r}
homicide_df <- read_csv(
  file = "Data/homicide-data.csv",
  na = c("NA", "",".", "na")) %>%
  drop_na() %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    victim_age = as.numeric(victim_age),
    victim_race = as_factor(victim_race),
    solve_status = factor(case_when(
      disposition %in% c("Closed without arrest", "Open/No arrest") ~ 0,
      disposition == "Closed by arrest" ~ 1,),
      labels = c("Unresolved", "Resolved")
    )
  ) %>% 
  filter(
    !(city_state %in% 
        c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")
      ),
    victim_race %in% c("Black", "White")
  ) 

```
## Prediction of Unresolved vs Resolved in Baltimore 
```{r}
balt_log_reg <- homicide_df %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(solve_status ~ victim_age + victim_sex + victim_race,
      data = .,
      family = binomial()
  )

balt_log_reg %>%
  broom::tidy() %>%
  filter(term == "victim_sexMale") %>% 
  mutate(
    adjusted_OR = exp(estimate),
    adjusted_OR_ci_lower = exp(estimate - (1.96 * std.error)),
    adjusted_OR_ci_upper = exp(estimate + (1.96 * std.error))
  ) %>% 
  select(adjusted_OR:adjusted_OR_ci_upper, p.value)

```
## Logistic Regression for each City
```{r}
log_model_city <- homicide_df %>% 
  group_by(city_state) %>% 
  nest(data = -city_state) %>%
  mutate(
    models = 
      map(data, 
          \(x) glm(x$solve_status ~ x$victim_age + x$victim_sex + x$victim_race,
          data = .,
          family = binomial())
      )
  )


```


# Problem 3
