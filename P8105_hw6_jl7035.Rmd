---
title: "P8105_HW6_jl7035"
author: "Jeffrey Lin"
date: "2024-12-02"
output: html_document
---

# Load Libraries
```{r}
library(tidyverse)

```

# Problem 1 

## Load and Clean Data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

```
## Peform Boostrap
```{r}
bootstrap_df <- weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, \(samp) lm(tmax ~ tmin, data = samp)),
    results = map(models, broom::tidy),
    summary = map(models, broom::glance),
    r_squared = map_dbl(summary, \(x) x$r.squared),
    log_beta_prod = map_dbl(results, \(x) log(prod(x$estimate)))
  ) %>% 
  select(-models,-results, -summary, -strap)
```

## Distribution of R-squared

```{r}
bootstrap_df %>% 
  ggplot(aes(x = r_squared)) +
  geom_density() + 
  xlab(label = "R-Squared") +
  ggtitle(label = "Distribution of R-Squared Values")

```
Examining the distribution of R-squared values, it appears that the R-squared 
for a linear model with minimum temperature as a predictor of max temperature 
tends to center at a little above 0.91. 

## Distribution of log(beta_1 * beta_0)

```{r}
bootstrap_df %>% 
  ggplot(aes(x = log_beta_prod)) + 
  geom_density() +
  xlab(label = "Log(Beta_0 * Beta_1") +
  ggtitle(label = "Distribution of Log(Beta_0 * Beta_1)")
```
Examining the distribution of Log(Beta_0 * Beta_1) values, it appears that the
values for a linear model with minimum temperature as a predictor of max temperature 
tends to center between 2.00 and 2.025. 

## Identify 95% confidence Interval for R-Squared

```{r}
bootstrap_df %>% 
  summarize(
    lower_ci = quantile(r_squared, 0.025), 
    upper_ci = quantile(r_squared, 0.975)
  )
```
## Identify the 95% confidence interval of Log (Beta_0 * Beta_1) 

```{r}
bootstrap_df %>% 
  summarize(
    lower_ci = quantile(log_beta_prod, 0.025), 
    upper_ci = quantile(log_beta_prod, 0.975)
  )
```

# Problem 2 

## Load in Data
```{r}
homicide_df <- read_csv(
  file = "Data/homicide-data.csv",
  na = c("NA", "",".", "na")) %>%
  drop_na() %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    victim_age = as.numeric(victim_age),
    victim_race = as_factor(victim_race),
    solve_status = factor(case_when(
      disposition %in% c("Closed without arrest", "Open/No arrest") ~ 0,
      disposition == "Closed by arrest" ~ 1,),
      labels = c("Unresolved", "Resolved")
    )
  ) %>% 
  filter(
    !(city_state %in% 
        c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")
      ),
    victim_race %in% c("Black", "White"),
    victim_sex %in% c("Female", "Male")
  ) 

```
## Prediction of Unresolved vs Resolved in Baltimore 
```{r}
balt_log_reg <- homicide_df %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(solve_status ~ victim_age + victim_sex + victim_race,
      data = .,
      family = binomial()
  )

balt_log_reg %>%
  broom::tidy(conf.int = TRUE) %>%
  filter(term == "victim_sexMale") %>% 
  mutate(
    adjusted_OR = exp(estimate),
    adjusted_OR_ci_lower = exp(conf.low),
    adjusted_OR_ci_upper = exp(conf.high)
  ) %>% 
  select(adjusted_OR:adjusted_OR_ci_upper, p.value)
```
## Logistic Regression for each City
```{r}
log_model_city <- homicide_df %>% 
  group_by(city_state) %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(data, 
        \(x) glm(x$solve_status ~ x$victim_age + x$victim_sex + x$victim_race,
        data = .,
        family = binomial())),
    summary = map(models, \(x) broom::tidy(x, conf.int = TRUE))
  ) %>% 
  unnest(summary) %>% 
  filter(term == "x$victim_sexMale") %>% 
  mutate(
    adjusted_OR = exp(estimate),
    adjusted_OR_ci_lower = exp(conf.low),
    adjusted_OR_ci_upper = exp(conf.high),
  ) %>% 
  select(city_state, adjusted_OR:adjusted_OR_ci_upper, p.value)
```

# OR and CI of Solved Crime Rates of Men compared to Women by City
```{r}
log_model_city %>%  
  ggplot(aes(x = reorder(city_state, adjusted_OR), y = adjusted_OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = adjusted_OR_ci_lower, ymax = adjusted_OR_ci_upper)) +
  xlab(label = "City-State") +
  ylab(label = "Adjusted Odds Ratio") +
  ggtitle("Odds Ratio of Crimes being Solved of Men Compared to Women by
          City") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
```
We see the lowest adjusted odds ratio in New York City, where male victims of 
crimes are less likely to have their crimes resolved. Inversely, the highest 
odds ratio is found Albuquerque, where male victims of crimes are more likely to
have their crimes resolved. It is also interesting to note that the cities with 
the highest adjusted odds ratios also had the largest confidence intervals. 
These large confidence intervals cross the threshold of 1, so it we cannot be 
certain at a 95% confidence level that male victims are more likely to have 
their crimes resolved. Also broadly, it appears that the confidence intervals 
are increasing as the odds ratio increases.

# Problem 3

## Load and Clean Data
```{r}
birthweight_df <- 
  read_csv(
    file = "Data/birthweight.csv",
    na = c("NA", "na", ".", "")
  ) %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = factor(babysex, levels = c(1,2), labels = c("male", "female")),
    frace = factor(
      frace, levels = c(1, 2, 3, 4, 8, 9), 
      labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    malform = factor(
      malform, levels = c(0, 1), labels = c("absent", "present")),
    mrace = factor(
      mrace, levels = c(1, 2, 3, 4, 8), 
      labels = c("White", "Black", "Asian", "Puerto Rican", "Other")
      )
  )

```

